{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fluid-israeli",
   "metadata": {},
   "source": [
    "# Machine Learning & Application \n",
    "## 2021-2022\n",
    "# Projet Rubik's cube\n",
    "\n",
    "Le projet porte sur un problème d'apprentissage supervisé. Le problème fait parti des données du [challenge des données](https://challengedata.ens.fr/challenges/20) ENS et s'intitule \"Solve 2x2x2 Rubik's cube\" et est présenté par la société LumenAI. Une [vidéo](https://www.college-de-france.fr/video/stephane-mallat/2019) décrivant le problème se trouve sur le site du collège de France. \n",
    "\n",
    "Les autres challenges sont aussi très intéressants, mais nécessitent plus de connaissances en machine learning (par exemple de l'apprentissage sur des séries temporelles, sur des images, des sons, du texte, etc...). D'où le choix de ce challenge dont les données sont très proches de problèmes sur lesquels on a travaillé.\n",
    "\n",
    "La résolution d'un rubik's cube peut être vu comme un problème d'intelligence artificielle (par exemple en utilisant des techniques de recherches avec des heuristiques). On peut même étudier le graphe du jeu du point de vue de la théorie des graphes et découvrir qu'en fait il existe toujours un chemin relativement court à une solution.\n",
    "\n",
    "ex dans la litérature:\n",
    " * \"The Diameter of the Rubik's Cube Group Is Twenty\", *T. Rokicki, H. Kociemba, M. Davidson, and J. Dethridge*, SIAM Review, 2014, Vol. 56, No. 4 : pp. 645-670.\n",
    " * \"Solving Rubik’s Cube Using Graph Theory\", Khemani C., Doshi J., Duseja J., Shah K., Udmale S., Sambhe V. (2019) in: Verma N., Ghosh A. (eds) Computational Intelligence: Theories, Applications and Future Directions - Volume I. Advances in Intelligent Systems and Computing, vol 798. Springer, Singapore. \n",
    " \n",
    "Ici, on a une base de données qui contient la description de rubik's cubes ainsi que le nombre minimal de coups pour les résoudre. On ne sait pas comment les problèmes ont été générés (est-ce que cela entraine un biais dans les problèmes, est-ce que plusieurs problèmes similaires sont présents dans la base? (Ici par similaire, on pourrait peut être avoir deux problèmes qui apparaissent dans la base, mais en permuttant certaines couleurs, on aurait peut-être exactement le même problème!)). Cependant, on vous demande de constuire un modèle pour nous aider à prédire le nombre de coups minimal pour un problème donné. Ensuite, vous pourriez utiliser ce modèle dans un algorithme de recherche étudié en cours d'IA.\n",
    "\n",
    "On peut le voir comme un problème de regression où il faut deviner le nombre minimal de coups pour résoudre le rubik's cube, ou comme un problème de classification où la classe d'un état du rubik's cube est le nombre minimal de coups pour le résoudre (donc on pourrait avoir au plus 19 classes). Toutes les méthodes que l'on a vu en cours peuvent s'appliquer.\n",
    "\n",
    "## Les données et le site du challenge\n",
    "\n",
    "Le projet s'effectue en binôme. Vous devez ouvrir un compte pour le binôme sur le site du challenge, choisissez de participer seul (le binôme sera un seul participant au challenge), puis inscrivez-vous au challenge du cours *M1 MIAGE Dauphine - PSL - 2021-2022*.\n",
    "\n",
    "Vous aurez accès à trois ensembles: \n",
    " * `x_train` qui contient la description de 1.837.079 différents rubik's cubes. Chaque rubik's cube est représenté par 25 attributs (lisez la description sur le site du challenge).\n",
    " * `y_train` qui contient le nombre minimal de coups pour résoudre chacun des 1.837.079 différents rubik's cubes. \n",
    " Ces données sont vos données d'entrainement.\n",
    " * enfin `x_test` qui contient la description de 1.837.080 nouveaux rubik's cubes. Vous ne connaissez pas le nombre minimal pour chacun de ces problèmes. \n",
    " \n",
    "Pour participer aux challenges, il vous faudra uploader sur le site votre prédiction sur les rubik's cubes du fichier `x_test` et le site du challenge vous donnera un score. Pour ce score, le site utilise l'erreur moyenne absolue: pour les n=1.837.080 exemples du fichier test, on fait la moyenne entre le vrai nombre minimal de coups $y_i$ et votre prédiction $z_i$: \n",
    "$$ \\frac{\\sum_{i=1}^n |y_i-z_i|}{n}$$\n",
    "\n",
    "Malheureusement (pour vous), le site ne vous donnera pas plus d'information que votre score, vous ne pourrez pas savoir quelles sont vos bonnes prédictions et quelles sont vos erreurs. Pire, le site vous permettra d'uploader une prédiction que deux fois par jour!\n",
    "\n",
    "\n",
    "## Soumission et rapport\n",
    "\n",
    "Un des membres du binôme devra remplir le formulaire Forms de l'équipe Teams du cours (onglet General) pour enregistrer les membres du binôme et le login du binôme qui utilisé sur le site du challenge ENS. \n",
    "Avant le **jeudi 2 décembre à 12h** vous devez 1) avoir créé votre compte pour le binôme et inscrit le binôme sur le challenge du cours, et 2) rempli les informations sur le formulaire Forms.\n",
    "\n",
    "Vous pouvez faire le projet seul, mais vous serez évalué comme un binôme. Si vous tenez absolument à former un trinôme, contactez moi par email, mais sachez que dès lors, les attentes seront plus élevées.\n",
    "\n",
    "Le deadline pour le projet sera le **dimanche 20 décembre 23:59**\n",
    "Vous devrez à ce moment là avoir fait trois choses:\n",
    "* avoir rendu un rapport\n",
    "* avoir rendu un notebook jupyter ou collab contenant le code pour générer votre solution\n",
    "* avoir soumis une solution sur le site du challenge ENS.\n",
    "\n",
    "Le notebook et le rapport seront à soumettre sous myCourse.\n",
    "\n",
    "Le rapport est un document **pdf** et devra être un document structuré qui explique vos choix, explique votre solution et donne votre résultat. Ne présentez ni le cours, ni le contexte, seul votre travail est important. Le rapport est de **6** pages maximum au format A4 (sans utiliser une taille de police inférieure strictement à 12). Vous pouvez ajouter une annexe à ce rapport (au format pdf ou sous la forme d'un notebook jupyter), étant entendu que le lecteur n'est pas obligé de lire l'annexe. Votre mission est de proposer un modèle de prédiction pour ce problème, votre rapport doit justifier comment vous avez répondu (complètement ou pas) à cette mission (par exemple, vous pouvez décrire ce que vous avez essayé, ce qui a marché ou non, pourquoi vous avez essayé autre chose...). Une autre façon de décrire ce qu'on attend du rapport est la suivante: votre manageur a donné à plusieurs équipes la même tâche d'apprentissage supervisé. Vous devez lui présenter dans ce rapport des arguments qui justifient la qualité de votre approche et de vos résultats. Votre manageur connait le problème, mais n'est pas forcément un expert du domaine. A vous de le convaincre d'utiliser votre solution! (attention, si vous connaissez aussi les limitations de votre solution, il est bon de les exposer aussi!). \n",
    "\n",
    "L'évaluation portera sur la qualité de votre analyse, même si vos résultats sont peu concluant. Pour caricaturer, un modèle qui gagnerait la compétition sans pouvoir expliquer ce qu'il a fait n'aura pas une bonne note pour le projet du cours (mais bravo, il a gagné la compétition!). Autre caricature, un projet qui applique un seul algorithme et conclue que ça ne fonctionne pas bien n'aura pas non plus une bonne note.\n",
    "\n",
    "Une soutenance sera organisée lors de la première semaine de cours (après les examens). Elle permettra de compléter l'évaluation et de vous donner un retour sur votre travail.\n",
    " Cette soutenance ne demande aucune préparation de votre part. Elle durera une douzaine/quinzaine de minutes par groupe. La soutenance consistera en un échange au sujet de vos résultats et votre rapport. Si la soutenance fait apparaître qu’un des membres n’a pas beaucoup contribué, sa note pourra être revue à la baisse. Egalement, on pourra vous demander de montrer le code et de fournir les résultats que vous avez obtenu lors des exercices d’implémentation des TDs.\n",
    "\n",
    "Ce projet compte pour 40% de la note de l’UE. Il est donc souhaitable que la note corresponde au travail de votre groupe, et non aux conseils d’autres groupes, d’autres étudiants ou d’internet. Si vous utilisez des sources (articles de recherche, posts sur internet, etc...), vous devez mentionnez vos sources dans le rapport (sinon, cela s'appelle du plagiat, et cela peut être puni par un conseil de discipline).\n",
    "\n",
    "Les quelques lignes de code ci-dessous lisent simplement les fichiers sources et affiche la taille des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acknowledged-battery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taille des données:\n",
      "X: (1837079, 24)\n",
      "Y: (1837079,)\n",
      "test: (1837080, 24)\n",
      "[[4 1 1 ... 3 5 3]\n",
      " [6 5 2 ... 3 5 2]\n",
      " [5 3 3 ... 2 5 2]\n",
      " ...\n",
      " [3 3 3 ... 1 5 2]\n",
      " [5 3 5 ... 6 5 1]\n",
      " [3 1 4 ... 2 5 3]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "df_train_in = pd.read_csv(\"train_input.csv\")\n",
    "df_train_in = df_train_in.drop(columns=['ID'])\n",
    "X_complet = df_train_in.to_numpy()\n",
    "df_train_out = pd.read_csv(\"train_output.csv\")\n",
    "df_train_out = df_train_out.distance\n",
    "y_complet = df_train_out.to_numpy()\n",
    "print(\"taille des données:\")\n",
    "print(\"X:\", X_complet.shape)\n",
    "print(\"Y:\", y_complet.shape)\n",
    "\n",
    "df_test_in = pd.read_csv(\"test_input.csv\")\n",
    "df_test_in = df_test_in.drop(columns=['ID'])\n",
    "Xtest = df_test_in.to_numpy()\n",
    "print(\"test:\", Xtest.shape)\n",
    "\n",
    "print(X_complet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "facial-grounds",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moyenne coups : 10.66639050362015\n",
      "mediane coups : 11.0\n",
      "Nom des classes:  [11  9 12 10  8  7 13  6  5  3  4  2 14  1]\n",
      "Nombre d'observations dans chacune des classes:\n",
      " 1          3\n",
      "2         13\n",
      "3         60\n",
      "4        267\n",
      "5       1128\n",
      "6       4485\n",
      "7      16529\n",
      "8      57074\n",
      "9     180254\n",
      "10    465294\n",
      "11    675426\n",
      "12    391268\n",
      "13     45140\n",
      "14       138\n",
      "Name: distance, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"moyenne coups : \" + str(df_train_out.distance.mean()))\n",
    "print(\"mediane coups : \" + str(df_train_out.distance.median()))\n",
    "print(\"Nom des classes: \", df_train_out.distance.unique())\n",
    "print(\"Nombre d'observations dans chacune des classes:\\n\", df_train_out.distance.value_counts().sort_index(ascending=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c28de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in df_train_in.iterrows():\n",
    "    for idx2, row2 in df_train_in.iterrows():\n",
    "        if(idx2 < idx):\n",
    "            pass\n",
    "            #on a déjà comparé ces deux lignes entre elles\n",
    "        else:\n",
    "            tab = [0, 0, 0, 0, 0, 0]\n",
    "            if(idx != idx2):\n",
    "                i = 0\n",
    "                while(i<24):\n",
    "                    if(tab[row[i]-1] == 0):\n",
    "                        tab[row[i]-1] = row2[i]\n",
    "                    elif(tab[row[i]-1] != row2[i]):\n",
    "                        i = 30\n",
    "                    i += 1\n",
    "                if(i < 30):\n",
    "                    print(row)\n",
    "                    print(y[idx][1])\n",
    "                    print(row2)\n",
    "                    print(y[idx2][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2141dd40",
   "metadata": {},
   "source": [
    "Notre première approche a été de tester le score que l'on aurait en faisant de l'aléatoire.\n",
    "Comme les données d'entraînement et de test ont le même nombre (à 1 près) de données, on a repris les mêmes proportions des différentes distances dans les données d'entraînement (on les a affiché plus haut) et on les a remises aléatoirement sur les données de test\n",
    "Cette première approche nous a permis d'obtenir un score de 1.2475036470921244 sur le site du challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23ecbec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdm_distance = df_train_out.distance.tolist()\n",
    "rdm_distance.append(11) #dans le jeu de test il y a une ligne en plus, on a donc rajouté 11 comme distance car c'est la distance majoritaire\n",
    "random.shuffle(rdm_distance)\n",
    "df_test_out_rdm = pd.DataFrame(list(zip(df_test_in.ID.tolist(), rdm_distance)), columns=['ID', 'distance'])\n",
    "df_test_out_rdm.to_csv('test_output_random.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dba131e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16529\n",
      "57074\n",
      "180254\n",
      "465294\n",
      "675426\n",
      "391268\n",
      "45140\n"
     ]
    }
   ],
   "source": [
    "#sélection d'une partie des données\n",
    "#sélection de 50% des données pour les classes les plus volumineuses\n",
    "\n",
    "df_train_out_sep = [[]for i in range(7)]\n",
    "\n",
    "for idx, valeur in df_train_out.iterrows():\n",
    "    if(valeur.distance == 7):\n",
    "        df_train_out_sep[0].append(idx)\n",
    "    elif(valeur.distance == 8):\n",
    "        df_train_out_sep[1].append(idx)\n",
    "    elif(valeur.distance == 9):\n",
    "        df_train_out_sep[2].append(idx)\n",
    "    elif(valeur.distance == 10):\n",
    "        df_train_out_sep[3].append(idx)\n",
    "    elif(valeur.distance == 11):\n",
    "        df_train_out_sep[4].append(idx)\n",
    "    elif(valeur.distance == 12):\n",
    "        df_train_out_sep[5].append(idx)\n",
    "    elif(valeur.distance == 13):\n",
    "        df_train_out_sep[6].append(idx)\n",
    "\n",
    "for i in range(len(df_train_out_sep)):\n",
    "    print(len(df_train_out_sep[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "135b8302",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_train_out_sep)): #mélanger avant d'en garder seulement 50%\n",
    "    random.shuffle(df_train_out_sep[i])\n",
    "\n",
    "df_train_out_sep2 = []\n",
    "for i in range(len(df_train_out_sep)):\n",
    "    for j in range(round(len(df_train_out_sep[i])/2)): #on prend que 50% de la base de données\n",
    "        df_train_out_sep2.append(df_train_out.loc[df_train_out_sep[i][j]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afe8ade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, valeur in df_train_out.iterrows():\n",
    "    if(valeur.distance < 7 or valeur.distance == 14):\n",
    "        df_train_out_sep2.append(valeur)\n",
    "\n",
    "df_train_out_sep3 = pd.DataFrame(data=df_train_out_sep2,index=[i for i in range(len(df_train_out_sep2))], columns=['ID','distance'])\n",
    "df_train_out_reduit = df_train_out_sep3.sample(frac=1).reset_index(drop=True) #melanger pour que ce ne soit pas trié par classe\n",
    "df_train_out_reduit.to_csv('train_out_reduit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fe29889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             ID  pos0  pos1  pos2  pos3  pos4  pos5  pos6  pos7  pos8  ...  \\\n",
      "0       1426607     4     3     2     6     1     6     6     6     1  ...   \n",
      "1        293988     5     3     5     1     5     6     6     1     6  ...   \n",
      "2        648371     3     4     1     3     2     2     6     3     4  ...   \n",
      "3       1405346     1     3     2     6     5     5     6     4     4  ...   \n",
      "4          2611     3     1     5     5     2     4     6     6     2  ...   \n",
      "...         ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
      "921581   373362     5     3     1     2     2     6     6     1     2  ...   \n",
      "921582  1708502     3     2     6     4     2     3     6     5     1  ...   \n",
      "921583   648328     3     1     1     4     5     2     6     6     1  ...   \n",
      "921584  1622948     1     4     4     5     1     2     6     2     2  ...   \n",
      "921585  1819791     1     6     4     6     4     1     6     5     2  ...   \n",
      "\n",
      "        pos14  pos15  pos16  pos17  pos18  pos19  pos20  pos21  pos22  pos23  \n",
      "0           4      2      3      1      5      3      4      3      5      5  \n",
      "1           4      3      2      2      4      2      2      3      5      4  \n",
      "2           4      1      1      5      2      6      6      6      5      2  \n",
      "3           4      3      5      4      1      3      6      1      5      6  \n",
      "4           4      4      6      2      4      6      1      3      5      3  \n",
      "...       ...    ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
      "921581      4      4      1      6      4      3      6      5      5      5  \n",
      "921582      4      1      2      1      2      3      5      1      5      4  \n",
      "921583      4      3      2      5      4      3      1      6      5      2  \n",
      "921584      4      6      3      3      1      2      3      6      5      3  \n",
      "921585      4      2      3      3      1      2      3      4      5      1  \n",
      "\n",
      "[921586 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "df_train_out_reduit = pd.read_csv(\"train_out_reduit.csv\")\n",
    "train_in_red = []\n",
    "for idx, valeur in df_train_out_reduit.iterrows():\n",
    "    train_in_red.append(df_train_in.loc[valeur.ID])\n",
    "\n",
    "df_train_in_reduit = pd.DataFrame(data=train_in_red,index=[i for i in range(len(df_train_out_reduit))], columns=['ID','pos0','pos1','pos2','pos3','pos4','pos5','pos6','pos7','pos8','pos9','pos10','pos11','pos12','pos13','pos14','pos15','pos16','pos17','pos18','pos19','pos20','pos21','pos22','pos23'])\n",
    "df_train_in_reduit.to_csv('train_in_reduit.csv', index=False)\n",
    "print(df_train_in_reduit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d56eb211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  nom\n",
      "0   0    1\n",
      "1   1    1\n",
      "2   2    2\n",
      "3   3    3\n",
      "4   4    4\n",
      "5   5    3\n",
      "6   6    2\n",
      "7   7    1\n",
      "8   8    1\n",
      "   id  pos1  pos2\n",
      "0   0     1     4\n",
      "1   1     1     5\n",
      "2   2     2     7\n",
      "3   3     3     3\n",
      "4   4     4     5\n",
      "5   5     3     7\n",
      "6   6     2     0\n",
      "7   7     1     2\n",
      "8   8     1     9\n",
      "   id  nom\n",
      "0   3    3\n",
      "1   2    2\n",
      "2   4    4\n",
      "3   1    1\n",
      "4   0    1\n",
      "5   5    3\n",
      "   id  pos1  pos2\n",
      "0   3     3     3\n",
      "1   2     2     7\n",
      "2   4     4     5\n",
      "3   1     1     5\n",
      "4   0     1     4\n",
      "5   5     3     7\n"
     ]
    }
   ],
   "source": [
    "#visualisation code précédent\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "test = [[]for i in range(2)]\n",
    "test2 = np.array([[0,1], [1,1], [2,2], [3,3], [4,4], [5,3], [6,2], [7,1], [8,1]])\n",
    "inp = np.array([[0,1,4], [1,1,5], [2,2,7], [3,3,3], [4,4,5], [5,3,7], [6,2,0], [7,1,2], [8,1,9]])\n",
    "test3 = pd.DataFrame(data=test2,columns=['id','nom'])\n",
    "inp2 = pd.DataFrame(data=inp,columns=['id','pos1', 'pos2'])\n",
    "\n",
    "print(test3)\n",
    "print(inp2)\n",
    "\n",
    "for idx, valeur in test3.iterrows():\n",
    "    if(valeur.nom == 1):\n",
    "        test[0].append(idx)\n",
    "    elif(valeur.nom == 2):\n",
    "        test[1].append(idx)\n",
    "\n",
    "\n",
    "for i in range(len(test)):\n",
    "    random.shuffle(test[i])\n",
    "\n",
    "test4 = []\n",
    "for i in range(len(test)):\n",
    "    for j in range(round(len(test[i])/2)): #on prend que 50% de la base de données\n",
    "        test4.append(test3.loc[test[i][j]])\n",
    "\n",
    "for idx, valeur in test3.iterrows():\n",
    "    if(valeur.nom > 2):\n",
    "        test4.append(valeur)\n",
    "    \n",
    "test5 = pd.DataFrame(data=test4,index=[i for i in range(len(test4))], columns=['id','nom'])\n",
    "test5_shuffled=test5.sample(frac=1).reset_index(drop=True)\n",
    "print(test5_shuffled)\n",
    "\n",
    "inp3 = []\n",
    "for idx, valeur in test5_shuffled.iterrows():\n",
    "    inp3.append(inp2.loc[valeur.id])\n",
    "\n",
    "inp4 = pd.DataFrame(data=inp3,index=[i for i in range(len(test5_shuffled))], columns=['id','pos1', 'pos2'])\n",
    "print(inp4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fe0488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df_train_in_reduit = pd.read_csv(\"train_in_reduit.csv\")\n",
    "X_reduit = df_train_in_reduit.to_numpy()\n",
    "df_train_out_reduit = pd.read_csv(\"train_out_reduit.csv\")\n",
    "y_reduit = df_train_out_reduit.to_numpy()\n",
    "\n",
    "df_test_in = pd.read_csv(\"test_input.csv\")\n",
    "Xtest = df_test_in.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "131259b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_reduit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18904/1101170268.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mkppv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'euclidean'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mkppv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_reduit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_reduit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkppv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_test_in\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_reduit' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "kppv = KNeighborsClassifier(n_neighbors=5,  metric='euclidean')\n",
    "kppv.fit(X_reduit, y_reduit)\n",
    "out = kppv.predict(Xtest)\n",
    "print(out)\n",
    "\n",
    "df_test_out_reduit_kppv = pd.DataFrame(list(zip(df_test_in.ID.tolist(), out)), columns=['ID', 'distance'])\n",
    "df_test_out_reduit_kppv.to_csv('test_out_reduit_kppv.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6567a4b",
   "metadata": {},
   "source": [
    "### Réseau de neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dea6f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11 11 11 ... 11 11 11]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(200,150,100), max_iter=10000)\n",
    "mlp.fit(X_complet, y_complet)\n",
    "out = mlp.predict(Xtest)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "265e74da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moyenne coups : 10.999888954209942\n",
      "Nom des classes:  [ 1 10 11 12]\n",
      "Nombre d'observations dans chacune des classes:\n",
      " [      0       6       0       0       0       0       0       0       0\n",
      "       0     459 1836300     315]\n"
     ]
    }
   ],
   "source": [
    "print(\"moyenne coups : \" + str(out.mean()))\n",
    "print(\"Nom des classes: \", np.unique(out))\n",
    "print(\"Nombre d'observations dans chacune des classes:\\n\", np.bincount(out))\n",
    "df_test_in = pd.read_csv(\"test_input.csv\")\n",
    "df_test_out_neural = pd.DataFrame(list(zip(df_test_in.ID.tolist(), out)), columns=['ID', 'distance'])\n",
    "df_test_out_neural.to_csv('test_output_neural.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b1003c",
   "metadata": {},
   "source": [
    "### Data processing : représentation par les coins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72541e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "while(j < len(df_train_in)):\n",
    "    l = df_train_in.iloc[j].tolist()\n",
    "    for i in range(1,9):\n",
    "        if(l[i] == l[i+8] or l[i] == l[i+16] or l[i+8] == l[i+16]):\n",
    "            print(l)\n",
    "            j = len(df_train_in)\n",
    "            break;\n",
    "    j += 1\n",
    "j = 0\n",
    "while(j < len(df_test_in)):\n",
    "    l = df_test_in.iloc[j].tolist()\n",
    "    for i in range(1,9):\n",
    "        if(l[i] == l[i+8] or l[i] == l[i+16] or l[i+8] == l[i+16]):\n",
    "            print(l)\n",
    "            j = len(df_test_in)\n",
    "            break;\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b36f917",
   "metadata": {},
   "source": [
    "On remarque que les 8 coins correspondent sûrement aux pos0-pos8-pos16, pos1-pos9-pos17, etc.\n",
    "\n",
    "On va donc tenter de réduire la taille des données d'entrainement et de test en entrée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d081b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>451</td>\n",
       "      <td>143</td>\n",
       "      <td>123</td>\n",
       "      <td>125</td>\n",
       "      <td>652</td>\n",
       "      <td>263</td>\n",
       "      <td>645</td>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>643</td>\n",
       "      <td>541</td>\n",
       "      <td>215</td>\n",
       "      <td>143</td>\n",
       "      <td>265</td>\n",
       "      <td>263</td>\n",
       "      <td>645</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>514</td>\n",
       "      <td>314</td>\n",
       "      <td>364</td>\n",
       "      <td>213</td>\n",
       "      <td>362</td>\n",
       "      <td>152</td>\n",
       "      <td>645</td>\n",
       "      <td>562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>521</td>\n",
       "      <td>526</td>\n",
       "      <td>436</td>\n",
       "      <td>143</td>\n",
       "      <td>236</td>\n",
       "      <td>123</td>\n",
       "      <td>645</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>436</td>\n",
       "      <td>236</td>\n",
       "      <td>152</td>\n",
       "      <td>541</td>\n",
       "      <td>132</td>\n",
       "      <td>341</td>\n",
       "      <td>645</td>\n",
       "      <td>625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1837074</th>\n",
       "      <td>1837074</td>\n",
       "      <td>215</td>\n",
       "      <td>154</td>\n",
       "      <td>312</td>\n",
       "      <td>346</td>\n",
       "      <td>526</td>\n",
       "      <td>341</td>\n",
       "      <td>645</td>\n",
       "      <td>632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1837075</th>\n",
       "      <td>1837075</td>\n",
       "      <td>231</td>\n",
       "      <td>314</td>\n",
       "      <td>326</td>\n",
       "      <td>541</td>\n",
       "      <td>652</td>\n",
       "      <td>436</td>\n",
       "      <td>645</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1837076</th>\n",
       "      <td>1837076</td>\n",
       "      <td>312</td>\n",
       "      <td>346</td>\n",
       "      <td>341</td>\n",
       "      <td>265</td>\n",
       "      <td>251</td>\n",
       "      <td>451</td>\n",
       "      <td>645</td>\n",
       "      <td>632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1837077</th>\n",
       "      <td>1837077</td>\n",
       "      <td>562</td>\n",
       "      <td>346</td>\n",
       "      <td>514</td>\n",
       "      <td>132</td>\n",
       "      <td>512</td>\n",
       "      <td>326</td>\n",
       "      <td>645</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1837078</th>\n",
       "      <td>1837078</td>\n",
       "      <td>364</td>\n",
       "      <td>125</td>\n",
       "      <td>451</td>\n",
       "      <td>236</td>\n",
       "      <td>132</td>\n",
       "      <td>562</td>\n",
       "      <td>645</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1837079 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0    1    2    3    4    5    6    7    8\n",
       "0              0  451  143  123  125  652  263  645  643\n",
       "1              1  643  541  215  143  265  263  645  312\n",
       "2              2  514  314  364  213  362  152  645  562\n",
       "3              3  521  526  436  143  236  123  645  145\n",
       "4              4  436  236  152  541  132  341  645  625\n",
       "...          ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
       "1837074  1837074  215  154  312  346  526  341  645  632\n",
       "1837075  1837075  231  314  326  541  652  436  645  152\n",
       "1837076  1837076  312  346  341  265  251  451  645  632\n",
       "1837077  1837077  562  346  514  132  512  326  645  341\n",
       "1837078  1837078  364  125  451  236  132  562  645  413\n",
       "\n",
       "[1837079 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_train_in_coins = []\n",
    "for idx, row in df_train_in.iterrows():\n",
    "    tab = [0,0,0,0,0,0,0,0,0]\n",
    "    l = row.tolist()\n",
    "    tab[0] = idx\n",
    "    for i in range(1,9):\n",
    "        tab[i] = str(l[i]) + str(l[i+8]) + str(l[i+16])\n",
    "    mat_train_in_coins.append(tab)\n",
    "df_train_in_coins = pd.DataFrame(mat_train_in_coins)\n",
    "df_train_in_coins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e4c82b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>263</td>\n",
       "      <td>314</td>\n",
       "      <td>625</td>\n",
       "      <td>125</td>\n",
       "      <td>132</td>\n",
       "      <td>436</td>\n",
       "      <td>645</td>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>326</td>\n",
       "      <td>143</td>\n",
       "      <td>123</td>\n",
       "      <td>541</td>\n",
       "      <td>125</td>\n",
       "      <td>256</td>\n",
       "      <td>645</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>215</td>\n",
       "      <td>463</td>\n",
       "      <td>625</td>\n",
       "      <td>143</td>\n",
       "      <td>362</td>\n",
       "      <td>123</td>\n",
       "      <td>645</td>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>341</td>\n",
       "      <td>463</td>\n",
       "      <td>263</td>\n",
       "      <td>213</td>\n",
       "      <td>541</td>\n",
       "      <td>152</td>\n",
       "      <td>645</td>\n",
       "      <td>562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>625</td>\n",
       "      <td>415</td>\n",
       "      <td>152</td>\n",
       "      <td>634</td>\n",
       "      <td>623</td>\n",
       "      <td>231</td>\n",
       "      <td>645</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1837075</th>\n",
       "      <td>1837075</td>\n",
       "      <td>625</td>\n",
       "      <td>541</td>\n",
       "      <td>123</td>\n",
       "      <td>512</td>\n",
       "      <td>314</td>\n",
       "      <td>263</td>\n",
       "      <td>645</td>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1837076</th>\n",
       "      <td>1837076</td>\n",
       "      <td>632</td>\n",
       "      <td>125</td>\n",
       "      <td>123</td>\n",
       "      <td>541</td>\n",
       "      <td>431</td>\n",
       "      <td>625</td>\n",
       "      <td>645</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1837077</th>\n",
       "      <td>1837077</td>\n",
       "      <td>134</td>\n",
       "      <td>652</td>\n",
       "      <td>326</td>\n",
       "      <td>541</td>\n",
       "      <td>251</td>\n",
       "      <td>643</td>\n",
       "      <td>645</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1837078</th>\n",
       "      <td>1837078</td>\n",
       "      <td>152</td>\n",
       "      <td>236</td>\n",
       "      <td>436</td>\n",
       "      <td>132</td>\n",
       "      <td>526</td>\n",
       "      <td>514</td>\n",
       "      <td>645</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1837079</th>\n",
       "      <td>1837079</td>\n",
       "      <td>413</td>\n",
       "      <td>541</td>\n",
       "      <td>152</td>\n",
       "      <td>213</td>\n",
       "      <td>526</td>\n",
       "      <td>632</td>\n",
       "      <td>645</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1837080 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0    1    2    3    4    5    6    7    8\n",
       "0              0  263  314  625  125  132  436  645  514\n",
       "1              1  326  143  123  541  125  256  645  364\n",
       "2              2  215  463  625  143  362  123  645  514\n",
       "3              3  341  463  263  213  541  152  645  562\n",
       "4              4  625  415  152  634  623  231  645  341\n",
       "...          ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
       "1837075  1837075  625  541  123  512  314  263  645  643\n",
       "1837076  1837076  632  125  123  541  431  625  645  364\n",
       "1837077  1837077  134  652  326  541  251  643  645  231\n",
       "1837078  1837078  152  236  436  132  526  514  645  413\n",
       "1837079  1837079  413  541  152  213  526  632  645  364\n",
       "\n",
       "[1837080 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_test_in_coins = []\n",
    "for idx, row in df_test_in.iterrows():\n",
    "    tab = [0,0,0,0,0,0,0,0,0]\n",
    "    l = row.tolist()\n",
    "    tab[0] = idx\n",
    "    for i in range(1,9):\n",
    "        tab[i] = str(l[i]) + str(l[i+8]) + str(l[i+16])\n",
    "    mat_test_in_coins.append(tab)\n",
    "df_test_in_coins = pd.DataFrame(mat_test_in_coins)\n",
    "df_test_in_coins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27f71b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_in_coins.to_csv(\"train_in_coins.csv\", index=False)\n",
    "df_test_in_coins.to_csv(\"test_in_coins.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea3f29aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taille des données:\n",
      "X: (1837079, 8)\n",
      "Y: (1837079,)\n",
      "test: (1837080, 8)\n",
      "[[451 143 123 ... 263 645 643]\n",
      " [643 541 215 ... 263 645 312]\n",
      " [514 314 364 ... 152 645 562]\n",
      " ...\n",
      " [312 346 341 ... 451 645 632]\n",
      " [562 346 514 ... 326 645 341]\n",
      " [364 125 451 ... 562 645 413]]\n"
     ]
    }
   ],
   "source": [
    "df_train_in_coins = pd.read_csv(\"train_in_coins.csv\")\n",
    "df_train_in_coins = df_train_in_coins.drop(columns=['ID'])\n",
    "X_complet_coins = df_train_in_coins.to_numpy()\n",
    "print(\"taille des données:\")\n",
    "print(\"X:\", X_complet_coins.shape)\n",
    "print(\"Y:\", y_complet.shape)\n",
    "\n",
    "df_test_in_coins = pd.read_csv(\"test_in_coins.csv\")\n",
    "df_test_in_coins = df_test_in_coins.drop(columns=['ID'])\n",
    "Xtest_coins = df_test_in_coins.to_numpy()\n",
    "print(\"test:\", Xtest_coins.shape)\n",
    "\n",
    "print(X_complet_coins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b4b36ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11 11 11 ... 11 11 11]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp_coins = MLPClassifier(hidden_layer_sizes=(200,150,100), max_iter=10000)\n",
    "mlp_coins.fit(X_complet_coins, y_complet)\n",
    "out_coins = mlp_coins.predict(Xtest_coins)\n",
    "print(out_coins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8030e63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moyenne coups : 11.0\n",
      "Nom des classes:  [11]\n",
      "Nombre d'observations dans chacune des classes:\n",
      " [      0       0       0       0       0       0       0       0       0\n",
      "       0       0 1837080]\n"
     ]
    }
   ],
   "source": [
    "print(\"moyenne coups : \" + str(out_coins.mean()))\n",
    "print(\"Nom des classes: \", np.unique(out_coins))\n",
    "print(\"Nombre d'observations dans chacune des classes:\\n\", np.bincount(out_coins))\n",
    "df_test_in = pd.read_csv(\"test_input.csv\")\n",
    "df_test_out_neural_coins = pd.DataFrame(list(zip(df_test_in.ID.tolist(), out_coins)), columns=['ID', 'distance'])\n",
    "df_test_out_neural_coins.to_csv('test_output_coins_neural.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee37d2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 11 10 ... 11 11 10]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "kppv_coins = KNeighborsClassifier(n_neighbors=14,  metric='euclidean')\n",
    "kppv_coins.fit(X_complet_coins, y_complet)\n",
    "out_kppv_coins = kppv_coins.predict(Xtest_coins)\n",
    "print(out_kppv_coins)\n",
    "\n",
    "df_test_out_coins_kppv = pd.DataFrame(list(zip(df_test_in.ID.tolist(), out_kppv_coins)), columns=['ID', 'distance'])\n",
    "df_test_out_coins_kppv.to_csv('test_output_coins_kppv.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12f395da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moyenne coups : 10.751028262242254\n",
      "Nom des classes:  [ 5  6  7  8  9 10 11 12 13]\n",
      "Nombre d'observations dans chacune des classes:\n",
      " [      0       0       0       0       0       1      31     275    3556\n",
      "   57231  504947 1097279  173563     197]\n"
     ]
    }
   ],
   "source": [
    "print(\"moyenne coups : \" + str(out_kppv_coins.mean()))\n",
    "print(\"Nom des classes: \", np.unique(out_kppv_coins))\n",
    "print(\"Nombre d'observations dans chacune des classes:\\n\", np.bincount(out_kppv_coins))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad18754d",
   "metadata": {},
   "source": [
    "#### Vérification coins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9df97e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = True\n",
    "for idx, row in df_train_in_coins.iterrows():\n",
    "    for c in row.tolist():\n",
    "        if((('1' in str(c) and not '6' in str(c)) or (not '1' in str(c) and '6' in str(c))) and (('2' in str(c) and not '4' in str(c)) or (not '2' in str(c) and '4' in str(c))) and (('3' in str(c) and not '5' in str(c)) or (not '3' in str(c) and '5' in str(c)))):\n",
    "            pass\n",
    "        else:\n",
    "            print(idx)\n",
    "            check = False\n",
    "            break\n",
    "    if(not check):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a072b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = True\n",
    "for idx, row in df_test_in_coins.iterrows():\n",
    "    for c in row.tolist():\n",
    "        if((('1' in str(c) and not '6' in str(c)) or (not '1' in str(c) and '6' in str(c))) and (('2' in str(c) and not '4' in str(c)) or (not '2' in str(c) and '4' in str(c))) and (('3' in str(c) and not '5' in str(c)) or (not '3' in str(c) and '5' in str(c)))):\n",
    "            pass\n",
    "        else:\n",
    "            print(idx)\n",
    "            check = False\n",
    "            break\n",
    "    if(not check):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4371ef26",
   "metadata": {},
   "source": [
    "A priori ok : 1 et 6, 2 et 4, 3 et 5 sont bien des faces opposées"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182d1a60",
   "metadata": {},
   "source": [
    "### Arbres de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5e483e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 11 11 ... 12 10 10]\n",
      "moyenne coups : 10.6484731203867\n",
      "Nom des classes:  [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "Nombre d'observations dans chacune des classes:\n",
      " [     0      3     15     91    280   1292   5107  18485  63392 189623\n",
      " 463590 648839 395566  50648    149]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree_coins = DecisionTreeClassifier()\n",
    "tree_coins.fit(X_complet_coins, y_complet)\n",
    "out_tree_coins = tree_coins.predict(Xtest_coins)\n",
    "print(out_tree_coins)\n",
    "\n",
    "df_test_in = pd.read_csv(\"test_input.csv\")\n",
    "df_test_out_coins_tree = pd.DataFrame(list(zip(df_test_in.ID.tolist(), out_tree_coins)), columns=['ID', 'distance'])\n",
    "df_test_out_coins_tree.to_csv('test_output_coins_tree.csv', index=False)\n",
    "print(\"moyenne coups : \" + str(out_tree_coins.mean()))\n",
    "print(\"Nom des classes: \", np.unique(out_tree_coins))\n",
    "print(\"Nombre d'observations dans chacune des classes:\\n\", np.bincount(out_tree_coins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5cf2190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11 12 11 ... 11  9 12]\n",
      "moyenne coups : 10.647561347355586\n",
      "Nom des classes:  [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14]\n",
      "Nombre d'observations dans chacune des classes:\n",
      " [     0      6     10     56    305   1305   5011  18383  62983 190615\n",
      " 464107 649334 394113  50691    161]\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X_complet, y_complet)\n",
    "out_tree = tree.predict(Xtest)\n",
    "print(out_tree)\n",
    "\n",
    "df_test_out_tree = pd.DataFrame(list(zip(df_test_in.ID.tolist(), out_tree)), columns=['ID', 'distance'])\n",
    "df_test_out_tree.to_csv('test_output_tree.csv', index=False)\n",
    "print(\"moyenne coups : \" + str(out_tree.mean()))\n",
    "print(\"Nom des classes: \", np.unique(out_tree))\n",
    "print(\"Nombre d'observations dans chacune des classes:\\n\", np.bincount(out_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f17aac4",
   "metadata": {},
   "source": [
    "### Classification naïve bayésienne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b12c3890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11 11 11 ... 11 11 11]\n",
      "moyenne coups : 11.0\n",
      "Nom des classes:  [11]\n",
      "Nombre d'observations dans chacune des classes:\n",
      " [      0       0       0       0       0       0       0       0       0\n",
      "       0       0 1837080]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb_coins = GaussianNB()\n",
    "gnb_coins.fit(X_complet_coins, y_complet)\n",
    "out_gnb_coins = gnb_coins.predict(Xtest_coins)\n",
    "print(out_gnb_coins)\n",
    "\n",
    "df_test_out_coins_gnb = pd.DataFrame(list(zip(df_test_in.ID.tolist(), out_gnb_coins)), columns=['ID', 'distance'])\n",
    "df_test_out_coins_gnb.to_csv('test_output_coins_gnb.csv', index=False)\n",
    "print(\"moyenne coups : \" + str(out_gnb_coins.mean()))\n",
    "print(\"Nom des classes: \", np.unique(out_gnb_coins))\n",
    "print(\"Nombre d'observations dans chacune des classes:\\n\", np.bincount(out_gnb_coins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d0a63ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11 11 11 ... 11 11 11]\n",
      "moyenne coups : 10.828945391599712\n",
      "Nom des classes:  [ 1  2 11]\n",
      "Nombre d'observations dans chacune des classes:\n",
      " [      0    2850   31749       0       0       0       0       0       0\n",
      "       0       0 1802481]\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_complet, y_complet)\n",
    "out_gnb = gnb.predict(Xtest)\n",
    "print(out_gnb)\n",
    "\n",
    "df_test_out_gnb = pd.DataFrame(list(zip(df_test_in.ID.tolist(), out_gnb)), columns=['ID', 'distance'])\n",
    "df_test_out_gnb.to_csv('test_output_gnb.csv', index=False)\n",
    "print(\"moyenne coups : \" + str(out_gnb.mean()))\n",
    "print(\"Nom des classes: \", np.unique(out_gnb))\n",
    "print(\"Nombre d'observations dans chacune des classes:\\n\", np.bincount(out_gnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e288c74a",
   "metadata": {},
   "source": [
    "### Prétraitement / pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01b6ebb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11 11 11 ... 11 11 11]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), PCA(n_components=10), MLPClassifier(hidden_layer_sizes=(200,100,50), max_iter=10000))\n",
    "pipe.fit(X_complet, y_complet)\n",
    "out = pipe.predict(Xtest)\n",
    "print(out)\n",
    "#que des 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba10bfe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moyenne coups : 11.0\n",
      "Nom des classes:  [11]\n",
      "Nombre d'observations dans chacune des classes:\n",
      " [      0       0       0       0       0       0       0       0       0\n",
      "       0       0 1837080]\n"
     ]
    }
   ],
   "source": [
    "print(\"moyenne coups : \" + str(out.mean()))\n",
    "print(\"Nom des classes: \", np.unique(out))\n",
    "print(\"Nombre d'observations dans chacune des classes:\\n\", np.bincount(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120a76fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
